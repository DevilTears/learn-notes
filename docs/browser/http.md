# HTTP

## 网络模型

现在使用的是 TCP/IP 5层模型

1. 应用层（Http、https）
    到这里你有疑惑吗？比如前面网络层中，你是怎么知道接收方的 IP 地址的？前面说的子网络间的连接口--网关，又是个啥呢？

    到了应用层这里，那么我们先来回答下第一个疑问。
    我们在发出请求时，是有具体的请求地址的对吗？通过这个地址，我们就能知道接收端
    的 IP 地址。这里就要说到另一个协议 DNS。类似电话簿，我们在请求的时候，往往是
    www.baidu.com，通过 DNS 解析，我们就能查询到这个域名对应的 IP 地址。

    第二个问题，网关到底是咋子回事，他咋分配咋查找了。
    每个主机都有自己的 mac 地址，那你想过他的 IP 地址哪儿来的吗？
    再引入一个协议 DHCP。这个协议规定，每一个子网络中，有一台计算机负责管理本网络的所有IP地址，它叫做”DHCP服务器”。新的计算机加入网络，必须向”DHCP服务器”发送一个”DHCP请求”数据包，申请IP地址和相关的网络参数。

    新的主机有自己的 mac 地址，这时候它需要请求回来自己的 IP 地址。于是它在子网中发送一个以太网数据包，这个数据包中包含着
    以太网标头：
      有效的自身 mac 地址，和目标 mac 地址（即 当前子网络 DHCP 服务器地址），但是这时候它并不知道 目标 mac 地址，因此它填写了 FF-FF-FF-FF-FF-FF。
    IP 地址标头：
      自身 IP（并不知道，就设为默认的 0.0.0.0） 和 目标 IP（也不知道，就设为默认的 255.255.255.255）
    UDP 标头：
      自身端口 和 目标端口。这一部分是DHCP协议规定好的，发出方是68端口，接收方是67端口。
    这个数据包发出后，同一个子网络的每台计算机都收到了这个包。因为接收方的MAC地址是FF-FF-FF-FF-FF-FF，看不出是发给谁的，所以每台收到这个包的计算机，还必须分析这个包的IP地址，才能确定是不是发给自己的。当看到发出方IP地址是0.0.0.0，接收方是255.255.255.255，于是DHCP服务器知道”这个包是发给我的”，而其他计算机就可以丢弃这个包。

    那接下来，DHCP 服务器 就会像发送方回复一个 包含请求数据的数据包。包含着：
    以太网标头：
      DHCP mac 地址，和目标 mac 地址（请求主机的 mac 地址）
    IP 地址标头：
      DHCP IP 和 目标 IP（请求主机的 IP 地址：经过 DHCP 计算后分配的一个地址）
    UDP 标头：
      自身端口 和 目标端口。这一部分是DHCP协议规定好的，发出方是67端口，接收方是68端口。

    到这里每台主机的 IP 地址也被分配了，并且每个子网络中都有一个主机负责分配、查找子网下的 IP 地址（可以查找是因为，当前子网下每个主机的 IP 都是它分配的，所以它都知道）
2. 传输层(tcp)
    通过前 3 层我们已经实现了 主机之间的数据传输，那么还有问题，当前主机上运行着
    多个程序，那么我发送/接收到的这个数据是给哪个程序的呢？
    当你正在QQ聊天的时候，微信发送过来的消息内容呈现在了QQ界面，害怕吗？

    这个时候我们就需要一个新的参数了！这个参数就是端口。
    端口是 0 - 65535 之间的一个整数，正好 16 个二进制位。0 - 1023 的端口被系统占用。用户只能选择大于 1023 的端口。

    不管是浏览网页还是在线聊天，应用程序会随机选用一个端口，然后与服务器的相应端口联系。

    确切的说，传输层实现了端对端的服务，网络层只是实现了 主机 对 主机的服务。

    综上所述，我们就要依靠传输层的协议，对上面的数据包继续添加一个端口的字段。
    UDP 的数据包：
    标头：主要定义了发送端 与 接收端的端口号；数据部分也定义了具体的内容。然后把它放在 IP 地址数据包的数据部分。

    那传输层有 UDP 就好了呀，为什么又推出了 TCP 协议呢？
    UDP 没有确认数据发送、接收完整的能力。而 TCP 在 UDP 的基础上，添加了 3 次握手，4 次挥手的过程。每发出一个数据包都要求确认。如果有一个数据包遗失，就收不到确认，发出方就知道有必要重发这个数据包了。
    因此 基于 TCP 有确认数据的前提，那么可以说 TCP 相对于 UDP 来说，是在牺牲了速度的前提下，保证了数据的完整性。
3. 网络层(ip)
    网络层的诞生就是为了解决 数据链路层遗留的问题。在 mac 地址不能解决上述场景后，又引入了 ip 地址。
    所以 ip 地址需要具备哪些能力呢？
    1. 判断发送方与接收方是否在同一子网下
    2. 如果不在同一子网，则需要用 ip 网址 去发挥功效

    我们的 IP 数据包中包含着 标头和数据
    标头：版本、长度、IP 地址等信息；数据部分则是 IP 数据包的具体内容。

    IPV4 版本规定网络地址由 32 位二进制组成，IPV6 则是 64 位二进制组成。
    在 IPV4 下，一般将 IP 地址分成4段（IPV6 下分为 8 段），这个地址分为 2 部分，前一部分是网络部分，后一部分是主机。通过“子网掩码”可以明确区分出当前 IP 地址的 网络地址 与 主机地址。
    那此时 我们就能通过 IP 地址中解析出来的网络地址，来判断当前发送方与接收方是否在同一子网下。如果在同一子网下，那么通过广播的形式，我们就可以完成数据传输；
    如果不在同一子网下，那么则需要一个“网关”（两个自网络的连接处）。

    如果目标主机和本机不在同一个子网络，我们通过IP地址，子网掩码比较得出在同一个子网络的结果，然后交给本网络的网关A处理，网关A根据路由协议得到目标主机所在子网络的网关B，网关B再通过IP地址判断得出和目标主机在同一个子网络，然后再通过ARP协议获取Mac地址，发送！Success!
4. 数据链路层(以太网)
    在物理层的基础上，实现了 2 台设备之间可以通信，但是以何种形式去通信，仅仅发送二进制编码就可以实现有效通信吗？
    显而易见是不行的，所以出现了“以太网”协议，来规定信息之间应该以何种格式进行有效传输与解析。
    以太网规定，一组电信号构成一个数据包，叫做“帧”。每一帧分成两部分：标头 和 数据。
    标头需要包含：发送者信息、接受者信息、数据类型等等；数据则是数据包的具体内容。

    那现在我们的设备之间可以通信了，也规定了消息的规范，具备发送与接收的能力了。但是出现了另一个问题：
    我们在标头中添加了发送方与接收方，但是我们如何在网络中找到这个接收方，把信息给他呢？
    这时候，就需要用到 mac 地址了，mac 地址随着每台电脑出厂，都有一个唯一的标识！那我们只要知道接收方
    的 mac 地址 不就知道要发给谁了吗？但是这里又出现了 2 个问题：

    1. 发送发如何拿到接收方的 mac 地址
    2. 拿到接收方 mac 地址后，如何找到它

    解决：
    问题 1：被 ARP 协议解决了，ARP 可以帮助我们获得接收方的 mac 地址（关于这个协议，需要另外进行补充）
    问题 2：以太网通过广播的形式，来将发送的数据包广播在整个子网中，因为包内包含着接收方的信息，所以子网内的每个
    设备都可以判断这个接收方与自己的 mac 地址是否匹配，从而接收对应的数据包

    解决完这两个问题后，又有新的问题了，目前我们只实现了在同一子网中，通过广播传送数据，那么在实际运用中，有很大
    概率通信的双方并不在同一子网下，意味着并不能通过同一子网下的广播（广播只能在子网络内进行）形式去传递数据。那么非同一子网下该如何通信呢？

5. 物理层（硬件：电缆等）
    设备层面，通过硬件将 2 台设备接入网络，如通过电缆、无线网络等，使 2 台设备之间可以发送二进制编码进行通信

## http 是什么

全称超文本传输协议，是从 web 服务器传输 超文本标记语言到本地浏览器的传送协议

设计http最初的目的是为了提供一种发布 和 接收 html页面的方法

## http 和 https 发展史

1. http 0.9：只能 get 请求，不涉及数据传输
2. http 1.0：增加了 post、put、head、del、options 命令，不限制传输内容格式
3. http 1.1 持久连接、节约带宽、host域、管道机制、分块传输编码
4. http 2.0 多路复用、服务器推送、头信息压缩、二进制协议等

## 常见的http状态码和前端缓存

> 题目来源：2020.12 好未来

![http-code](https://deviltears.github.io/learn-notes/images/http-code.png)

- 200 ok（请求成功）
- 204 no content （请求成功，但是没有结果返回）
- 206 partial content （客户端请求一部分资源，服务端成功响应，返回一范围资源）
- 301 move permanently （永久性重定向,此请求和之后所有的请求都应该转到指定的 url）
- 302 found （临时性重定向, 只将本次请求重定向。以后的请求还应请求原地址）
- 303 see other （示由于请求对应的资源存在着另一个 URI，应使用 GET 方法定向获取请求的资源）
- 304 not modified （表示在客户端采用带条件的访问某资源时，服务端找到了资源，但是这个请求的条件不符合。跟重定向无关）
- 307 temporary redirect （跟302一个意思）
- 400 bad request （请求报文存在语法错误）
- 401 unauthorized （需要认证（第一次返回）或者认证失败（第二次返回））
- 403 forbidden （请求被服务器拒绝了）
- 404 not found （服务器上无法找到请求的资源）
- 405 not allowed (请求方法错误)
- 500 internal server error （服务端执行请求时发生了错误）
- 502 bad gateway（错误网关）
- 503 service unavailable （服务器正在超负载或者停机维护，无法处理请求）
- 504 gateway timeout (网关超时)

## 301和302的区别

> 题目来源：2020.12 好未来

302重定向只是暂时的重定向，搜索引擎会抓取新的内容而保留旧的地址，因为服务器返回302，所以，搜索搜索引擎认为新的网址是暂时的。而301重定向是永久的重定向，搜索引擎在抓取新的内容的同时也将旧的网址替换为了重定向之后的网址。

## HTTP/2的三大特性, 与HTTP/1.1的区别

HTTP/2的三大特性: **头部压缩、多路复用、Server Push**

HTTP/2在HTTP/1.1有几处基本的不同:

- HTTP/2是二进制协议而不是文本协议。不再可读，也不可无障碍的手动创建，改善的优化技术现在可被实施。
- 这是一个复用协议。并行的请求能在同一个链接中处理，移除了HTTP/1.x中顺序和阻塞的约束。
- 压缩了headers。因为headers在一系列请求中常常是相似的，其移除了重复和传输重复数据的成本。
- 其允许服务器在客户端缓存中填充数据，通过一个叫服务器推送的机制来提前请求。

### 二进制分帧层 & 多路复用

除了服务端推送，其他都是为了解决 http1 中的问题：

1. 在 keep-alive 推出之前，每一次请求，都需要重新建立一个 tcp 连接（意味着每个请求都要经历一次 3 次握手，4 次挥手），可想而知性能消耗，http1.1 中默认开启了keep-alive，可以在一定时间内，支持多个请求共用一个 tcp 连接（但是不同浏览器 保持连接时常（5/10/30分钟） 和 同时支持的请求个数（6-8个） 也不尽相同。）
2. 但是 http 的传输形式是“一问一答”的形式，一个请求对应一个响应，在 keep-alive 中，必须等待上一个请求结束才能发起下一个请求，所以后面的请求会被前面的请求阻塞。使用 pipe-line 可以连续发送一组没有依赖的请求，而不必等到上一个请求结束。但是 pipe-line 依然没有解决阻塞的问题，因为请求响应的顺序必须和请求发送的顺序一致，意味着后面的响应即使已经完成了，也必须要等待前面的请求响应返回之后，才会被返回，这就是线头阻塞。

而 http2 基于二进制分帧层，实现了多路复用。

多路复用：所有相同域名的请求，都通过一个 tcp 连接完成，而它比 keep-alive 好在哪里呢

1. 所有相同域名的请求，都通过一个 tcp 连接完成，没有像 keep-alive 一样有个数与时间的限制
2. 提出了 流 和 帧的概念，每一个请求就是一个流（每个流都有一个唯一标识和优先级），一个流由多个帧组成（每一帧的头部信息会标识自己属于哪个流），所以这些帧是可以交错传输的，然后在接收端通过帧头信息，将他们组合成完整的响应流信息，这样就解决了 线头阻塞问题。

### 头部压缩

http 的请求和响应都是由 状态行、请求/响应头部、消息主体 3 部分组成。一般而言，消息主体都会经过 gzip 压缩，但状态和和响应头却没经过任何处理，也就意味着 头部的 content-type, cookie、user-agent 等等一系列字段直接以纯文本传输。而且这些字段往往在每次请求间都没有任何改动，完全是一种浪费。
在 http2 中采用字典形式去维护首部字段，一份静态字典，一份动态字典

### HTTP3

http3 是 http2 的复用和压缩，最根本的变动是 将 http2 中的 tcp 协议改为使用 udp 协议，因为 udp 相较于 tcp 的3 次握手，4 次挥手来说，udp 是不安全的，所以它更快！当然 http3 中采用一定的机制，保证了它在快速的基础上，同时兼备安全性。

> 参考文献：
>
> 1. [MDN: HTTP/2](https://developer.mozilla.org/zh-CN/docs/Glossary/HTTP_2)
> 2. [MDN: HTTP/2 - 为了更优异的表现](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Basics_of_HTTP/Evolution_of_HTTP#http2_-_%E4%B8%BA%E4%BA%86%E6%9B%B4%E4%BC%98%E5%BC%82%E7%9A%84%E8%A1%A8%E7%8E%B0)

## 解决域名请求并发数量限制

浏览器使用并行连接，但它们将并行连接的总数限制为少量（通常为4，6个）

### HTTP 1.1情况下

Keep-Alive解决的核心问题：一定时间内，同一域名多次请求数据，只建立一次HTTP请求，其他请求可复用每一次建立的连接通道，以达到提高请求效率的问题。这里面所说的一定时间是可以配置的，不管你用的是Apache还是nginx。

如上面所说，在HTTP1.1中是默认开启了Keep-Alive，他解决了多次连接的问题，但是依然有两个效率上的问题：

- 第一个：串行的文件传输。当请求a文件时，b文件只能等待，等待a连接到服务器、服务器处理文件、服务器返回文件，这三个步骤。我们假设这三步用时都是1秒，那么a文件用时为3秒，b文件传输完成用时为6秒，依此类推。（注：此项计算有一个前提条件，就是浏览器和服务器是单通道传输）
- 第二个：连接数过多。我们假设Apache设置了最大并发数为300，因为浏览器限制，浏览器发起的最大请求数为6，也就是服务器能承载的最高并发为50，当第51个人访问时，就需要等待前面某个请求处理完成。

综上所述：通古多域名提高浏览器的下载速度。将静态文件图片打到两个或多个域名，这样浏览器就可以对 n * 6 个文件进行同时下载，避免了浏览器6个通道的限制，这样做的缺点也是明显的，1.DNS的解析时间会变长。2.增加了服务器的压力。

### HTTP 2情况下

HTTP/2的多路复用就是为了解决上述的两个性能问题，我们来看一下，他是如何解决的。

- 解决第一个：在HTTP1.1的协议中，我们传输的request和response都是基本于文本的，这样就会引发一个问题：所有的数据必须按顺序传输，比如需要传输：hello world，只能从h到d一个一个的传输，不能并行传输，因为接收端并不知道这些字符的顺序，所以并行传输在HTTP1.1是不能实现的。

![image](https://deviltears.github.io/learn-notes/images/http-code.png)

HTTP/2引入二进制数据帧和流的概念，其中帧对数据进行顺序标识，如下图所示，这样浏览器收到数据之后，就可以按照序列对数据进行合并，而不会出现合并后数据错乱的情况。同样是因为有了序列，服务器就可以并行的传输数据，这就是流所做的事情。

![image](https://deviltears.github.io/learn-notes/images/http-2.png)

- 解决第二个问题：HTTP/2对同一域名下所有请求都是基于流，也就是说同一域名不管访问多少文件，也只建立一路连接。同样Apache的最大连接数为300，因为有了这个新特性，最大的并发就可以提升到300，比原来提升了6倍！

### 总结

有了HTTP/2之后，根据上面讲的原理，我们就不用这么搞了，成本会更低。

> 参考文献：
> [浅析HTTP/2的多路复用](https://segmentfault.com/a/1190000011172823?utm_source=tag-newest)

## HTTP1和HTTP1.1缓存上区别

> 题目来源：2020.12-好未来

HTTP/1.1在1.0的基础上加入了一些cache的新特性，当缓存对象的Age超过Expire时变为stale对象，cache不需要直接抛弃stale对象，而是与源服务器进行重新激活（revalidation）。

## HTTPS的原理，加密方式，非对称还是对称

> 题目来源：2020.12-好未来

HTTPS 在内容传输的加密上使用的是对称加密，非对称加密只作用在证书验证阶段。

HTTPS要保证客户端与服务器端的通信安全，必须使用的对称加密算法，但是协商对称加密算法的过程，需要使用非对称加密算法来保证安全，然而直接使用非对称加密的过程本身也不安全，会有中间人篡改公钥的可能性，所以客户端与服务器不直接使用公钥，而是使用数字证书签发机构颁发的证书来保证非对称加密过程本身的安全。这样通过这些机制协商出一个对称加密算法，就此双方使用该算法进行加密解密。从而解决了客户端与服务器端之间的通信安全问题。

### https 解决了 http 中存在的问题

1. 不具备加密功能，信息明文展示，容易被窃听
2. 没有检查发送数据的完整行，容易被篡改
3. 没有校验通信人信息，因此可能遭遇伪装

### https 做的优化

1. 数据加密（对称加密：任何人只要有密钥，就可以解密）
2. 保证数据完整性
3. 身份认证（非对称加密：公开密钥 + 私有密钥，公开密钥可以随意发布，任何人都可以获得。私有密钥不能让其他任何人知道）

对称加密：客户端和服务端都使用 ca 证书中包含的公钥去加密解密
非对称加密：在对称加密的基础上，服务端增加了使用私钥解密的过程。

### https 的缺点

1. 需要花钱购买证书
2. 因为加密解密的过程，所以通信所消耗的资源更多

### https 的加密过程

https 在 http 基于 TCP/IP 的五层模型上，加了 SSL 协议，保证了安全性。主要通过身份认证时的“非对称加密” 与 通信时 “对称加密”来实现。当我们从浏览器地址栏输入一个 https 的 URL，到页面内容显示在屏幕上，中间经过了哪些？

1. 浏览器向服务端发送请求，同时附上一份随机生成的 session ticket1
2. 服务端向浏览器下发ca证书（证书内包含公钥、公钥算法、证书过期时间、证书有效域名、证书颁发机构等。），同时服务端将浏览器发送的 session ticket1 存储起来，并也生成一份随机 session ticket2，且将 session ticket2 下发给浏览器
3. 浏览器收到证书后，验证证书域名是否与当前域名相符、证书是否过期等。若验证都通过。则再生成一个 随机 session ticket3，并且通过下发的证书中的公钥以及加密算法对 session ticket3 进行加密，再把这个 session ticket3 返回给服务器。同时 浏览器用 session ticket1（浏览器生成）+ session ticket2（服务端生成）+ session ticket3（浏览器生成）组合成 session key
4. 服务端收到浏览器加密的 session ticket3 后，用配置的私钥，解密出 session ticket3 实质内容，同时也用 session ticket1（浏览器生成）+ session ticket2（服务端生成）+ session ticket3（浏览器生成）组合成 session key。如果两端这时候的 session key 一致，则表明身份验证通过。（3，4为非对称加密）
5. 后续双方使用 这个 session key 来对信息进行加密（这时候变为对称加密）

## HTTP和HTTPS的默认端口号

> 题目来源：2020.12-好未来

80, 443
